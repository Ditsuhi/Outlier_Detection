{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPt1mtevb3/6bkV1S/a0SCw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ditsuhi/Outlier_Detection/blob/main/LOF_Outlier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNzUBpxm2M6F"
      },
      "outputs": [],
      "source": [
        "# import all required libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neighbors import LocalOutlierFactor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h04_S31s2i8d",
        "outputId": "4968dd28-4e2e-402f-ae03-d9d820ca601e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4367, 24, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# The final version of the preprocessed dataset can be found at the following link: https://doi.org/10.5281/zenodo.6542247.\n",
        "# the path provided below can be changed depending your data location.\n",
        "\n",
        "data = pd.read_csv('/content/Madrid_Stations_2019.csv', header=None)\n",
        "data_test = pd.read_csv('/content/Madrid_Stations_2020.csv', header=None)\n",
        "fin_data_2019=data.to_numpy().reshape(-1,  24, 20)\n",
        "fin_data_2020=data_test.to_numpy().reshape(-1, 24,  20)\n",
        "fin_data_2020.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxQp6XUIGqOl"
      },
      "outputs": [],
      "source": [
        "# extract the features to which outlier detection technique was applied (all the features except wind direction, which is already went through One Hot Encoder (it means the data of wind direction is binary))\n",
        "\n",
        "fin_data = fin_data_2019[:, :, 0:10]\n",
        "fin_data_test = fin_data_2020[:, :, 0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLmtja5QHM5d",
        "outputId": "011461ab-6c9e-4ff8-d6de-b3c67776c7ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4344, 24, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "fin_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDsPpTUGkrO1"
      },
      "outputs": [],
      "source": [
        "# detect outliers using Local Outlier Factor\n",
        "\n",
        "combined_array= np.array([])\n",
        "combined_array_test= np.array([])\n",
        "\n",
        "for i in range(24):\n",
        "  for j in range(10):\n",
        "    df_fin_data = pd.DataFrame ()\n",
        "    df_fin_data_test = pd.DataFrame ()\n",
        "    df_fin_data['col'] = pd.DataFrame(fin_data[:, i, j])\n",
        "    df_fin_data_test['col'] = pd.DataFrame(fin_data_test[:, i, j])\n",
        "\n",
        "    # n_neighbors=all the samples, metric = \"manhattan\", \n",
        "    # contamination = 0.05 (contamination is the proportion of outliers in the dataset, and it was set to 0.05, meaning that 5% of the dataset was considered to be outliers)\n",
        "    \n",
        "    model = LocalOutlierFactor(n_neighbors=4344, metric = \"manhattan\", contamination = 0.05)\n",
        "    y_pred  = model.fit_predict(df_fin_data[['col']])\n",
        "    df_fin_data['anomaly']=y_pred\n",
        "    df_fin_data.loc[df_fin_data['anomaly']==-1, 'col'] = np.nan\n",
        "    df_fin_data['col'] = df_fin_data['col'].interpolate()\n",
        "    if df_fin_data['col'].isna().any():\n",
        "      df_fin_data['col']= df_fin_data['col'].bfill(limit=3)\n",
        "\n",
        "\n",
        "    model_test = LocalOutlierFactor(n_neighbors=4344, metric = \"manhattan\", contamination = 0.05)\n",
        "    y_pred_test  = model_test.fit_predict(df_fin_data_test[['col']])\n",
        "    df_fin_data_test['anomaly']=y_pred_test\n",
        "    df_fin_data_test.loc[df_fin_data_test['anomaly']==-1, 'col'] = np.nan\n",
        "    df_fin_data_test['col'] = df_fin_data_test['col'].interpolate()\n",
        "    if df_fin_data_test['col'].isna().any():\n",
        "      df_fin_data_test['col']= df_fin_data_test['col'].bfill(limit=3)\n",
        "\n",
        "\n",
        "    combined_array = np.append(combined_array, df_fin_data['col'].values.flatten())\n",
        "    combined_array_test =  np.append(combined_array_test, df_fin_data_test['col'].values.flatten())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldsRUqIUWqBq"
      },
      "outputs": [],
      "source": [
        "# combine two separated datasets: the part that went through outlier detection and the wind direction part that went through One Hot Encoder\n",
        "\n",
        "combined_array_resh = combined_array.reshape(-1, 4344)\n",
        "combined_array_test_resh = combined_array_test.reshape(-1, 4367)\n",
        "combined_array_resh_trans=np.transpose(combined_array_resh).reshape(-1, 24, 10)\n",
        "combined_array_test_resh_trans=np.transpose(combined_array_test_resh).reshape(-1, 24, 10)\n",
        "data_2019_outlier = np.concatenate((combined_array_resh_trans, fin_data_2019[:, :, 12:20]), axis=2)\n",
        "data_2020_outlier= np.concatenate((combined_array_test_resh_trans, fin_data_2020[:, :, 12:20]), axis=2)\n",
        "data_2020_outlier_resh = data_2020_outlier.reshape(-1)\n",
        "data_2019_outlier_resh = data_2019_outlier.reshape(-1)\n",
        "\n",
        "# save the results as csv files\n",
        "np.savetxt('Madrid_Stations_2020_WithoutOutlier_LOF_Upd.csv', data_2020_outlier_resh, delimiter=',')\n",
        "np.savetxt('Madrid_Stations_2019_WithoutOutlier_LOF_Upd.csv', data_2019_outlier_resh, delimiter=',')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to check if there is any nan value in the dataset after outlier detection\n",
        "\n",
        "np.isnan(data_2020_outlier_resh).any()"
      ],
      "metadata": {
        "id": "EfVNjF43Wt8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if there is any nan value to show where those nan values are placed \n",
        "\n",
        "np.argwhere(np.isnan(data_2019_outlier))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Omml1jEMUJER",
        "outputId": "2e02ba11-6974-4f3c-e4c1-4b4257e0774a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([], shape=(0, 3), dtype=int64)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}